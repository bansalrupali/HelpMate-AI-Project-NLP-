{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836e7bcb-2c62-409b-8d19-d23f39f6a89a",
   "metadata": {},
   "source": [
    "# Introduction to Langchain and its Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc91d4-e6bc-4196-9cd6-9bd4e0b71986",
   "metadata": {},
   "source": [
    "LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides a high-level API that allows developers to chain together multiple LLMs, data sources, and tools to create complex applications. Here are some key features and capabilities of LangChain:\n",
    "\n",
    "# Key Features\n",
    "Modular Architecture: LangChain's modular design allows developers to easily swap out components, such as language models, data sources, and processing steps, without disrupting the entire application. This flexibility enables rapid experimentation and iteration.\n",
    "\n",
    "Unified Interface: Despite supporting multiple LLMs from various providers, LangChain offers a consistent and unified interface, abstracting away the complexities of interacting with different models.\n",
    "\n",
    "Memory Management: LangChain simplifies the management of conversational memory, enabling applications to maintain context and continuity across interactions. This feature is particularly valuable for building chatbots, virtual assistants, and other conversational AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34380be7-d9c6-4de0-8902-3c4abaa11ed4",
   "metadata": {},
   "source": [
    "# Chain Feature in Langchain\n",
    "\n",
    "The chain feature in LangChain allows you to create a sequence of operations that can be performed in a linear or branching manner. This is especially useful when you want to combine multiple language model queries, data retrieval operations, or processing steps into a single, cohesive workflow. Here’s an overview of the chain feature and its capabilities:\n",
    "\n",
    "# Chain Feature Overview\n",
    "Sequential Execution: Chains enable you to execute a series of steps in a defined order. Each step takes the output from the previous step as its input, allowing for complex workflows to be built in a modular and reusable manner.\n",
    "\n",
    "Branching and Conditional Logic: Chains can include conditional logic and branching, enabling you to create more dynamic and adaptable workflows. Depending on certain conditions, the chain can follow different paths to handle various scenarios.\n",
    "\n",
    "Integration of Multiple Components: Chains can integrate various components, such as different language models, data sources, and processing functions. This allows you to leverage the strengths of multiple tools and models in a single workflow.\n",
    "\n",
    "Error Handling: Chains can include error handling mechanisms to ensure robustness and reliability. If an error occurs at any step in the chain, you can define how to handle it and whether to continue or abort the workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706d4daf-ecd4-4045-a968-dd2544e45654",
   "metadata": {},
   "source": [
    "# Need for Langchain and RAG\n",
    "\n",
    "Limitation of LLM Training: While LLMs are trained on extensive public data, they lack training on proprietary, private data specific to individual problems.\n",
    "\n",
    "# Challenges of Fine-Tuning LLMs:\n",
    "\n",
    "Costly: Training LLMs requires significant financial resources.\n",
    "Inflexibility: Once trained, updating LLMs with new information is expensive and challenging.\n",
    "Lack of Observability: It's not clear how LLMs arrive at their conclusions when posed with a query.\n",
    "Advantages of Retrieval-Augmented Generation (RAG):\n",
    "\n",
    "No Training Required: RAG eliminates the need for costly retraining.\n",
    "Up-to-Date Information: Data is retrieved in real-time from sources, ensuring the information is current.\n",
    "Transparency: By showing the retrieved documents, RAG provides a more transparent and trustworthy process.\n",
    "LlamaIndex and Context Augmentation:\n",
    "\n",
    "Flexibility: Langchain allows LLMs to be used in various applications like chatbots, auto-complete, etc., without restrictions.\n",
    "Enhanced Relevance: Langchain enhances the relevance of LLM responses by incorporating specific, contextual data from diverse sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18acde93-3f72-437c-a4f2-1d9a2a99b872",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "LLMs are trained on enormous bodies of data but they aren't trained on your data. Retrieval-Augmented Generation (RAG) solves this problem by adding your data to the data LLMs already have access to. You will see references to RAG frequently in this documentation.\n",
    "\n",
    "In RAG, your data is loaded and prepared for queries or \"indexed\". User queries act on the index, which filters your data down to the most relevant context. This context and your query then go to the LLM along with a prompt, and the LLM provides a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc5057-28d4-40b5-82f9-db5b6d7961ee",
   "metadata": {},
   "source": [
    "# Significance of LangChain\n",
    "Primary Function : LangChain is a Python-based library that enables the development of custom NLP applications using large language models.\n",
    "Features:\tStands out for its versatility and adaptability in building robust applications with LLMs\n",
    "Key Features:\tSupports GPT-2, GPT-3, and T5 LLMs – Provides tokenization, text generation, and question-answering capabilities – Ideal for creating chatbots and summarizing lengthy documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c7fc33-2ac6-498b-b759-0990619eb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the needed libraries\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3cb684-784e-456b-be95-f0c65003e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='p_id: 17048614\n",
      "name: Khushal K Women Black Ethnic Motifs Printed Kurta with Palazzos & With Dupatta\n",
      "products: Kurta, Palazzos, Dupatta\n",
      "price: 5099\n",
      "colour: Black\n",
      "brand: Khushal K\n",
      "img: http://assets.myntassets.com/assets/images/17048614/2022/2/4/b0eb9426-adf2-4802-a6b3-5dbacbc5f2511643971561167KhushalKWomenBlackEthnicMotifsAngrakhaBeadsandStonesKurtawit7.jpg\n",
      "ratingCount: 4522\n",
      "avg_rating: 4.418398939\n",
      "description: Black printed Kurta with Palazzos with dupatta <br> <br> <b> Kurta design:  </b> <ul> <li> Ethnic motifs printed </li> <li> Anarkali shape </li> <li> Regular style </li> <li> Mandarin collar,  three-quarter regular sleeves </li> <li> Calf length with flared hem </li> <li> Viscose rayon machine weave fabric </li> </ul> <br> <b> Palazzos design:  </b> <ul> <li> Printed Palazzos </li> <li> Elasticated waistband </li> <li> Slip-on closure </li> </ul>Dupatta Length 2.43 meters Width:&nbsp;88 cm<br>The model (height 5'8) is wearing a size S100% Rayon<br>Machine wash\n",
      "p_attributes: {'Add-Ons': 'NA', 'Body Shape ID': '443,333,324,424', 'Body or Garment Size': 'Garment Measurements in', 'Bottom Closure': 'Slip-On', 'Bottom Fabric': 'Viscose Rayon', 'Bottom Pattern': 'Printed', 'Bottom Type': 'Palazzos', 'Character': 'NA', 'Dupatta': 'With Dupatta', 'Dupatta Border': 'Solid', 'Dupatta Fabric': 'Viscose Rayon', 'Dupatta Pattern': 'Printed', 'Main Trend': 'Indie Prints', 'Neck': 'Mandarin Collar', 'Number of Pockets': 'NA', 'Occasion': 'Festive', 'Ornamentation': 'NA', 'Pattern Coverage': 'Placement', 'Print or Pattern Type': 'Ethnic Motifs', 'Sleeve Length': 'Three-Quarter Sleeves', 'Sleeve Styling': 'Regular Sleeves', 'Slit Detail': 'NA', 'Stitch': 'Ready to Wear', 'Sustainable': 'Regular', 'Technique': 'Screen', 'Top Design Styling': 'Regular', 'Top Fabric': 'Viscose Rayon', 'Top Hemline': 'Flared', 'Top Length': 'Calf Length', 'Top Pattern': 'Printed', 'Top Shape': 'Anarkali', 'Top Type': 'Kurta', 'Waistband': 'Elasticated', 'Wash Care': 'Machine Wash', 'Weave Pattern': 'Regular', 'Weave Type': 'Machine Weave'}' metadata={'source': 'C:\\\\Users\\\\aminu\\\\OneDrive\\\\Documents\\\\Fashion Dataset v2.csv', 'row': 0}\n",
      "page_content='p_id: 16524740\n",
      "name: InWeave Women Orange Solid Kurta with Palazzos & Floral Print Dupatta\n",
      "products: Kurta, Palazzos, Floral Print Dupatta\n",
      "price: 5899\n",
      "colour: Orange\n",
      "brand: InWeave\n",
      "img: http://assets.myntassets.com/assets/images/16524740/2021/12/29/17ab2ac8-2e60-422d-9d20-2527415932361640754214931-STRAPPY-SET-IN-ORANGE-WITH-ORGANZA-DUPATTA-5961640754214349-2.jpg\n",
      "ratingCount: 1081\n",
      "avg_rating: 4.11933395\n",
      "description: Orange solid Kurta with Palazzos with dupatta<br><br><b>Kurta design: </b><ul><li>Solid</li><li>A-line shape</li><li>Regular style</li><li>Square neck, sleeveless shoulder straps</li><li>Calf length with straight hem</li><li>Viscose rayon machine weave fabric</li></ul><br><b>Palazzos design: </b><ul><li>Solid Palazzos</li><li>Elasticated waistband</li><li>Zip closure</li></ul><b>Dupatta Design:</b><ul><li>Floral Printed</li></ul>Kurta Fabric: Viscose rayon<br>Bottom Fabric:&nbsp;Viscose rayon<br>Dupatta Fabric: Organza<br>Hand washThe model (height 5'8) is wearing a size S\n",
      "p_attributes: {'Add-Ons': 'NA', 'Body Shape ID': '443,333,324,424', 'Body or Garment Size': 'Garment Measurements in', 'Bottom Closure': 'Zip', 'Bottom Fabric': 'Viscose Rayon', 'Bottom Pattern': 'Solid', 'Bottom Type': 'Palazzos', 'Character': 'NA', 'Dupatta': 'With Dupatta', 'Dupatta Border': 'Printed', 'Dupatta Fabric': 'Organza', 'Dupatta Pattern': 'Printed', 'Main Trend': 'NA', 'Neck': 'Square Neck', 'Number of Pockets': 'NA', 'Occasion': 'Fusion', 'Ornamentation': 'NA', 'Pattern Coverage': 'None', 'Print or Pattern Type': 'Solid', 'Sleeve Length': 'Sleeveless', 'Sleeve Styling': 'Shoulder Straps', 'Slit Detail': 'NA', 'Stitch': 'Ready to Wear', 'Sustainable': 'Regular', 'Technique': 'NA', 'Top Design Styling': 'Regular', 'Top Fabric': 'Viscose Rayon', 'Top Hemline': 'Flared', 'Top Length': 'Calf Length', 'Top Pattern': 'Solid', 'Top Shape': 'A-Line', 'Top Type': 'Kurta', 'Waistband': 'Elasticated', 'Wash Care': 'Hand Wash', 'Weave Pattern': 'Regular', 'Weave Type': 'Machine Weave'}' metadata={'source': 'C:\\\\Users\\\\aminu\\\\OneDrive\\\\Documents\\\\Fashion Dataset v2.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "#LangChain implements a CSV Loader that will load CSV files into a sequence of Document objects. \n",
    "#Each row of the CSV file is translated to one document.\n",
    "file_path = r\"C:\\Users\\aminu\\OneDrive\\Documents\\Fashion Dataset v2.csv\"\n",
    "loader = CSVLoader(file_path=file_path)\n",
    "data = loader.load()\n",
    "for record in data[:2]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b85a0571-1713-49ca-8574-279cffce98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the OpenAI API key\n",
    "import os\n",
    "filepath = r\"C:\\Users\\aminu\\OneDrive\\Documents\\open_ai_secret_key_2.txt\"\n",
    "with open(filepath,'r') as f:\n",
    "  openai_api_key = \" \".join(f.readlines())\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a309ed-91aa-432b-af4a-70e9d8da8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2a298a-756a-4f6a-a9dd-a6c48c221fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of OpenAIEmbeddings\n",
    "# The model parameter specifies the name of the model to use\n",
    "embedding = OpenAIEmbeddings(model = \"text-embedding-ada-002\")\n",
    "\"\"\"\n",
    "Documentation:\n",
    "The OpenAIEmbeddings class is used to generate embeddings (numerical representations of text) using OpenAI's language model. \n",
    "In this instance, the 'text-embedding-ada-002' model is specified. This model is part of OpenAI's suite of text embedding models, \n",
    "designed to provide high-quality embeddings for a wide range of natural language processing tasks.\n",
    "Attributes:\n",
    "- model: A string representing the name of the embedding model to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c158f74-a606-472e-9070-b01efe0bfe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (2.10.6)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (3.15.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (1.68.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (0.15.1)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.4-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aminu\\anaconda3\\envs\\python311\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "   ---------------------------------------- 0.0/611.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/611.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 611.1/611.1 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.6-cp311-cp311-win_amd64.whl (151 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.0 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading mmh3-5.1.0-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.20.1-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.3 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/11.3 MB 1.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/11.3 MB 1.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.3/11.3 MB 1.3 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.6/11.3 MB 1.3 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.8/11.3 MB 1.4 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.4/11.3 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.3 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.3 MB 1.4 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.9/11.3 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.3 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.4/11.3 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.7/11.3 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.9/11.3 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.2/11.3 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.3 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 5.5/11.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 5.5/11.3 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.8/11.3 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.0/11.3 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.3 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.8/11.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.1/11.3 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.3/11.3 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.6/11.3 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.9/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.1/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.4/11.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.7/11.3 MB 945.2 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.9/11.3 MB 949.6 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.2/11.3 MB 950.7 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.4/11.3 MB 961.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.3 MB 958.7 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.0/11.3 MB 968.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.2/11.3 MB 974.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.3 MB 988.4 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.3 MB 995.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
      "Downloading httptools-0.6.4-cp311-cp311-win_amd64.whl (88 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "Downloading watchfiles-1.0.4-cp311-cp311-win_amd64.whl (284 kB)\n",
      "Downloading websockets-15.0-cp311-cp311-win_amd64.whl (176 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53885 sha256=afd34cafd48e71de2842fd7df67a09c6f5f11c0b3af7b73e6b3fea9e2cedceb6\n",
      "  Stored in directory: c:\\users\\aminu\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, durationpy, zipp, websockets, pyreadline3, pyproject_hooks, pyasn1, opentelemetry-util-http, opentelemetry-proto, oauthlib, mmh3, importlib-resources, httptools, googleapis-common-protos, chroma-hnswlib, cachetools, bcrypt, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, opentelemetry-exporter-otlp-proto-common, importlib-metadata, humanfriendly, build, opentelemetry-api, google-auth, fastapi, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.9 google-auth-2.38.0 googleapis-common-protos-1.68.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 importlib-resources-6.5.2 kubernetes-32.0.1 mmh3-5.1.0 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rsa-4.9 starlette-0.45.3 uvicorn-0.34.0 watchfiles-1.0.4 websockets-15.0 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b52d8c-4b96-4bdd-8f6a-00ed084b284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b83992d4-7461-4f27-be9b-77cb5e62d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector store instance using the Chroma class\n",
    "# 'documents' parameter specifies the data to be embedded\n",
    "# 'embedding' parameter specifies the embedding model instance to be used\n",
    "# 'persist_directory' parameter specifies the directory to save the embedded vectors\n",
    "vectorstore = Chroma.from_documents(documents = data, \n",
    "                                    embedding = embedding, \n",
    "                                    persist_directory = \"./Myntra_dataset_embedding\")\n",
    "\"\"\"\n",
    "Documentation:\n",
    "The Chroma class is used to create a vector store from a set of documents using specified embeddings. \n",
    "This allows for efficient storage and retrieval of vector representations of the documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfa0ba19-3c8e-4829-b810-e46610a13277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever instance from the vector store using the Chroma class\n",
    "# 'search_type' parameter specifies the type of search to be used (e.g., 'mmr' for Maximal Marginal Relevance)\n",
    "# 'search_kwargs' parameter specifies additional keyword arguments for the search, including:\n",
    "# - 'k': The number of top results to return\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type = 'mmr', \n",
    "                                     search_kwargs = {'k': 3, \n",
    "                                                      'lambda_mult': 0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97e88bef-8f6b-4bbe-b039-0f73566b110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fef19f2-0663-422a-8c07-8b5e60bce5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template string for a professional conversation between a human and an AI\n",
    "# The AI is designed to be concise and provide specific details from its context\n",
    "\n",
    "TEMPLATE = '''\n",
    "The following is a professional conversation between a human and an AI. \n",
    "The AI is concise and provides lots of specific details from its context. \n",
    "\n",
    "Current conversation : \n",
    "{message_log}\n",
    "\n",
    "Human:\n",
    "{question}\n",
    "\n",
    "AI:\n",
    "\n",
    "To answer the question, use only the following context:\n",
    "{context}\n",
    "\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(TEMPLATE)\n",
    "\n",
    "\"\"\"\n",
    "Documentation:\n",
    "The TEMPLATE string defines the structure for a professional conversation between a human and an AI. \n",
    "It includes placeholders for the message log, the human's question, and the context to be used by the AI in its response.\n",
    "Parameters:\n",
    "- message_log: A placeholder for the current conversation's message log.\n",
    "- question: A placeholder for the human's question.\n",
    "- context: A placeholder for the specific context to be used by the AI in its response.\n",
    "\n",
    "The PromptTemplate class is used to create a template instance from the defined template string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ce1575c-b937-45e9-86cb-3a4817074b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aminu\\anaconda3\\envs\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "# Create a chat instance using the ChatOpenAI class\n",
    "# 'model_name' parameter specifies the name of the model to use\n",
    "# 'model_kwargs' parameter provides additional keyword arguments for the model (e.g., 'seed' for setting a seed value)\n",
    "# 'max_tokens' parameter specifies the maximum number of tokens to generate in the response\n",
    "chat = ChatOpenAI(model_name = 'gpt-4', \n",
    "                  model_kwargs = {'seed':365},\n",
    "                  max_tokens = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3921655a-442b-4ef1-87f8-97b4c05c43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat memory instance using the ConversationSummaryMemory class\n",
    "# 'llm' parameter specifies the language model to be used (in this case, an instance of ChatOpenAI)\n",
    "# 'memory_key' parameter specifies the key for storing the message log in the memory\n",
    "\n",
    "chat_memory = ConversationSummaryMemory(llm = ChatOpenAI(), memory_key = 'message_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8172f785-ae36-4473-ac6e-4eb4e2bb142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function \"ask_a_query\" to take the user's fashion related question and give the response\n",
    "\n",
    "def ask_a_query(question):\n",
    "\n",
    "# Create a chain of operations using various components to handle the conversation flow\n",
    "# 'retriever' provides the context for the current conversation\n",
    "# 'RunnablePassthrough' passes the question through without modification\n",
    "# 'RunnablePassthrough.assign' assigns the message log by loading memory variables using RunnableLambda\n",
    "# 'itemgetter' extracts the 'message_log' from the loaded memory variables\n",
    "# The prompt template, chat model, and string output parser are then used in sequence\n",
    "\n",
    " chain1 = (\n",
    "           {'context' : retriever,\n",
    "           'question':RunnablePassthrough()}|\n",
    "           RunnablePassthrough.assign(\n",
    "            message_log = RunnableLambda(chat_memory.load_memory_variables)\n",
    "            | \n",
    "            itemgetter('message_log')) \n",
    "        | prompt_template \n",
    "        | chat \n",
    "        | StrOutputParser()\n",
    "    )\n",
    " \"\"\"\n",
    "Documentation:\n",
    "The chain1 variable defines a sequence of operations to process a conversation between a human and an AI.\n",
    "Components:\n",
    "- retriever: Provides the context for the current conversation.\n",
    "- RunnablePassthrough: Passes the question through without modification.\n",
    "- RunnablePassthrough.assign: Assigns the message log by loading memory variables using RunnableLambda.\n",
    "- RunnableLambda: A lambda function used to load memory variables from the chat memory.\n",
    "- itemgetter: Extracts the 'message_log' from the loaded memory variables.\n",
    "- prompt_template: A template for structuring the AI's response.\n",
    "- chat: An instance of the ChatOpenAI class used to generate the AI's response.\n",
    "- StrOutputParser: Parses the AI's response into a string format.\"\"\"\n",
    "\n",
    "# Invoke the chain of operations defined in 'chain1' with the given question\n",
    "# 'question' parameter is the human's query to be processed through the chain\n",
    "    \n",
    " response = chain1.invoke(question)\n",
    "\n",
    "# Save the conversation context to the chat memory\n",
    "# 'inputs' parameter specifies the input data (e.g., the question asked by the human)\n",
    "# 'outputs' parameter specifies the output data (e.g., the response generated by the AI)\n",
    "    \n",
    " chat_memory.save_context(inputs = {'input':question}, \n",
    "                             outputs = {'output':response})\n",
    "\n",
    " return print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5750a9c5-57b4-45d2-8609-a874282293a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample question\n",
    "question = \"Can you suggest green palazzos?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "31db8037-0237-4f69-b751-7df214763c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, one option is the DORIYA Women Green Palazzos, priced at 1799. These are green woven palazzos with a solid color and opaque. The fit is straight with an elasticated waistband and it is made from a woven cotton fabric. It is recommended to machine-wash this item. The image can be found at this [link](http://assets.myntassets.com/assets/images/18622938/2022/6/4/d3e00a71-3012-45f3-a753-18fdc72a377b1654341599166DORIYAWomenGreenPalazzos1.jpg).\n"
     ]
    }
   ],
   "source": [
    "#Calling the function to get a response\n",
    "ask_a_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f0e68d47-2f4b-4d61-b434-aa698551df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry but the details about the available sizes of DORIYA Women Green Palazzos are not available in the provided documents.\n"
     ]
    }
   ],
   "source": [
    "#Asking a follow up question\n",
    "question = \"What are the sizes available in it?\"\n",
    "ask_a_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3698dd92-0235-47c2-951b-58e06776882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documents, I suggest the following party wear kurtas:\n",
      "\n",
      "1. Khushal K Women Green Ethnic Motifs Printed Gotta Patti Kurta with Trousers & Dupatta priced at 5699. It is an Anarkali shaped, green, printed Kurta with trousers and a matching dupatta. The kurta fabric is a viscose rayon machine weave, adorned with Gotta Patti detail and featuring a round neck and three-quarter flared sleeves. The trousers have an elastic waistband and slip-on closure. The outfit is best suited for festive occasions and it is advisable to machine wash it.\n",
      "\n",
      "2. Prakrti Pink & White Ethnic Motifs Printed Pure Cotton Pleated Kurti priced at 2199. This is a pink and white straight kurti with Ethnic motif print. The kurti has a mandarin collar, three-quarter sleeves, and is made of machine-weave pure cotton. The fabric care recommends a hand wash.\n",
      "\n",
      "3. Biba Women Cream-Coloured & Blue Printed Straight Kurti priced at 1299. A cream, blue, and grey colored kurti with a round neck, a printed panel on the front, three-quarter sleeves, and a\n"
     ]
    }
   ],
   "source": [
    "ask_a_query(\"recommend some party wear kurtas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
